{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3JuPEUMyr8P5I6CyZGFFg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kejuto/Test_task/blob/main/Test_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "IgHp2Z-tVEB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ec5a99-55c9-4b17-eb13-6a0b3516714b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/my-drive; to attempt to forcibly remount, call drive.mount(\"/content/my-drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Поключение к google диску для использования таблицы в google colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/my-drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/my-drive/MyDrive/depressed_or_not.csv')\n",
        "print(data.head())  # Отображение первых нескольких строк"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5X5-_iOgJQU",
        "outputId": "cdb81489-e0c0-41d9-ebac-d62fca4ca2a3"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survey_id  Ville_id  sex  Age  Married  Number_children  education_level  \\\n",
            "0        926        91    1   28        1                4               10   \n",
            "1        747        57    1   23        1                3                8   \n",
            "2       1190       115    1   22        1                3                9   \n",
            "3       1065        97    1   27        1                2               10   \n",
            "4        806        42    0   59        0                4               10   \n",
            "\n",
            "   total_members  gained_asset  durable_asset  ...  incoming_salary  \\\n",
            "0              5      28912201       22861940  ...                0   \n",
            "1              5      28912201       22861940  ...                0   \n",
            "2              5      28912201       22861940  ...                0   \n",
            "3              4      52667108       19698904  ...                0   \n",
            "4              6      82606287       17352654  ...                1   \n",
            "\n",
            "   incoming_own_farm  incoming_business  incoming_no_business  \\\n",
            "0                  0                  0                     0   \n",
            "1                  0                  0                     0   \n",
            "2                  0                  0                     0   \n",
            "3                  1                  0                     1   \n",
            "4                  0                  0                     0   \n",
            "\n",
            "   incoming_agricultural  farm_expenses  labor_primary  lasting_investment  \\\n",
            "0               30028818       31363432              0            28411718   \n",
            "1               30028818       31363432              0            28411718   \n",
            "2               30028818       31363432              0            28411718   \n",
            "3               22288055       18751329              0             7781123   \n",
            "4               53384566       20731006              1            20100562   \n",
            "\n",
            "   no_lasting_investmen  depressed  \n",
            "0            28292707.0          0  \n",
            "1            28292707.0          1  \n",
            "2            28292707.0          0  \n",
            "3            69219765.0          0  \n",
            "4            43419447.0          0  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Попытка обучения модели привела к ошибке так как есть пропущенные значения, будем искать методы борьбы с этим\n",
        "# Для начала оценим количество пропущенных элементов\n",
        "missing_values = data.isnull().sum()\n",
        "print(missing_values[missing_values > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1asIqhixqi1n",
        "outputId": "5258e3a6-4dea-4c35-8c6b-8ea4a8e3f0a8"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_lasting_investmen    20\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler  # Импортируем MinMaxScaler\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X = data.drop('depressed', axis=1)  # Признаки\n",
        "y = data['depressed']  # Метки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализуем данные с использованием MinMaxScaler\n",
        "scaler = MinMaxScaler()  # Изменяем на MinMaxScaler\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Создаем и обучаем модель с учетом дисбаланса классов\n",
        "model = BalancedRandomForestClassifier(random_state=42)  # Используем BalancedRandomForestClassifier\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Делаем предсказания\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка модели\n",
        "print(confusion_matrix(y_test, y_pred))  # Матрица путаницы\n",
        "print(classification_report(y_test, y_pred))  # Отчет о классификации"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2O5pZp-Bx7a",
        "outputId": "34eb2259-36d7-44d3-f68a-e4f3b00ff901"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[135 104]\n",
            " [ 31  16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.56      0.67       239\n",
            "           1       0.13      0.34      0.19        47\n",
            "\n",
            "    accuracy                           0.53       286\n",
            "   macro avg       0.47      0.45      0.43       286\n",
            "weighted avg       0.70      0.53      0.59       286\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Оценив модель и точность, приходим к выводу что такие показатели точности нас не устраивают. Можно заметить что имеет место быть большой дисбаланс классов, это можно решить добавлив дубликатов класса 1."
      ],
      "metadata": {
        "id": "h1278-ft8gS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = data[data['depressed'] == 1]\n",
        "\n",
        "# Объединяем исходные данные с дубликатами\n",
        "data = pd.concat([data, duplicates])\n",
        "\n",
        "# Сброс индексов\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "1CnNWnkVC0kj"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X = data.drop('depressed', axis=1)  # Признаки\n",
        "y = data['depressed']  # Метки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализуем данные с использованием MinMaxScaler\n",
        "scaler = MinMaxScaler()  # Изменяем на MinMaxScaler\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Создаем и обучаем модель с учетом дисбаланса классов\n",
        "model = BalancedRandomForestClassifier(random_state=42)  # Используем BalancedRandomForestClassifier\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Делаем предсказания\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка модели\n",
        "print(confusion_matrix(y_test, y_pred))  # Матрица путаницы\n",
        "print(classification_report(y_test, y_pred))  # Отчет о классификации"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-cphlhL8Vdr",
        "outputId": "1912ab63-bfb7-4816-d0ae-b28910b96983"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[192  55]\n",
            " [ 16  71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.78      0.84       247\n",
            "           1       0.56      0.82      0.67        87\n",
            "\n",
            "    accuracy                           0.79       334\n",
            "   macro avg       0.74      0.80      0.76       334\n",
            "weighted avg       0.83      0.79      0.80       334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность существенно увеличилась то что нам и нужно было добавим еще дубликатов"
      ],
      "metadata": {
        "id": "XtjOf0aeHOfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = data[data['depressed'] == 1]\n",
        "\n",
        "# Объединяем исходные данные с дубликатами\n",
        "data = pd.concat([data, duplicates])\n",
        "\n",
        "# Сброс индексов\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "RvPa7w8pG40E"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X = data.drop('depressed', axis=1)  # Признаки\n",
        "y = data['depressed']  # Метки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализуем данные с использованием MinMaxScaler\n",
        "scaler = MinMaxScaler()  # Изменяем на MinMaxScaler\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Создаем и обучаем модель с учетом дисбаланса классов\n",
        "model = BalancedRandomForestClassifier(random_state=42)  # Используем BalancedRandomForestClassifier\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Делаем предсказания\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка модели\n",
        "print(confusion_matrix(y_test, y_pred))  # Матрица путаницы\n",
        "print(classification_report(y_test, y_pred))  # Отчет о классификации"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwEuYz7CG6Jr",
        "outputId": "26809053-c0b2-454e-b44b-ac86c225e5c4"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[252  12]\n",
            " [  0 355]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98       264\n",
            "           1       0.97      1.00      0.98       355\n",
            "\n",
            "    accuracy                           0.98       619\n",
            "   macro avg       0.98      0.98      0.98       619\n",
            "weighted avg       0.98      0.98      0.98       619\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавив дубликатов мы можем заметить что все характиристики точности значительно увеличили с 53 до 79. Добавив дубликаты два раза мы достигаем точности 96%. Я считаю это очень хорошей точностью и достаточно хорошо обученной моделью. Если хочется увеличить точность еще достаточно один раз добавить и мы уже достигаем почти космической точности в 98%. Как будто бы более может и не требоваться и соотвественно чем больше дубликатов тем больше затрат на обучение, поэтому это оптимальное количество дубликатов от 2 до 3. Вот моя модель предложенная для вашего датасета. Задача решена."
      ],
      "metadata": {
        "id": "jvXXZ754ECDP"
      }
    }
  ]
}